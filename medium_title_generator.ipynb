{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1294572,"sourceType":"datasetVersion","datasetId":748442}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Medium Article Title Generator using LSTM\n\nThis notebook implements a neural language model for generating Medium article titles using a Bidirectional LSTM architecture. The model learns patterns from existing Medium article titles and generates new title suggestions based on seed text.","metadata":{"_uuid":"8d0d3052-47b9-4a3a-aac2-685f1158cca0","_cell_guid":"b0776b6d-1810-4391-bcf3-df2f3e8008ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"7d103651-30a4-4b15-b7a8-f238981b7529","_cell_guid":"05eeaa71-78ab-466b-b771-5ea6c591a279","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T07:54:43.107209Z","iopub.execute_input":"2025-05-28T07:54:43.107526Z","iopub.status.idle":"2025-05-28T07:54:49.841667Z","shell.execute_reply.started":"2025-05-28T07:54:43.107494Z","shell.execute_reply":"2025-05-28T07:54:49.840711Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import Required Libraries\n\nLoading all necessary libraries for data processing, text preprocessing, and neural network implementation.","metadata":{"_uuid":"d04916c6-0445-4b58-a62a-78c261fb5228","_cell_guid":"43454f09-fee5-44a4-a7d5-f342542479d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport re\nimport os\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\nfrom tensorflow.keras.optimizers import Adam\n","metadata":{"_uuid":"219178a1-a395-4456-8c88-1eae4739c413","_cell_guid":"0bb9a9b2-137d-4c6f-adb7-4a477580e1fc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:09.064518Z","iopub.execute_input":"2025-05-28T08:36:09.064987Z","iopub.status.idle":"2025-05-28T08:36:22.693617Z","shell.execute_reply.started":"2025-05-28T08:36:09.064960Z","shell.execute_reply":"2025-05-28T08:36:22.692920Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load and Explore Dataset\n\nLoading the Medium articles dataset and examining its structure to understand the data we're working with.","metadata":{"_uuid":"06d936e9-e24c-4190-adc4-f903ff0fa468","_cell_guid":"60a50e8b-2234-4c88-bab4-e31971111ec6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"medium_data = pd.read_csv(\"/kaggle/input/medium-articles-dataset/medium_data.csv\")\nprint(\"First 10 rows of the dataset:\")\nmedium_data.head(10)","metadata":{"_uuid":"4542e2c4-35e9-4005-80dd-589efa00ac71","_cell_guid":"7d99b520-70c1-47ba-a96f-a8d8bbb58035","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.694855Z","iopub.execute_input":"2025-05-28T08:36:22.695404Z","iopub.status.idle":"2025-05-28T08:36:22.785187Z","shell.execute_reply.started":"2025-05-28T08:36:22.695377Z","shell.execute_reply":"2025-05-28T08:36:22.784391Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Dataset shape: {medium_data.shape}\")\nprint(f\"Total articles: {medium_data.shape[0]}, Features: {medium_data.shape[1]}\")\nmedium_data.shape","metadata":{"_uuid":"4b3317d2-e300-4762-8efd-26a8cfe22cfc","_cell_guid":"aacf48c6-73db-4c26-98a7-28b89d701676","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.786214Z","iopub.execute_input":"2025-05-28T08:36:22.786600Z","iopub.status.idle":"2025-05-28T08:36:22.791777Z","shell.execute_reply.started":"2025-05-28T08:36:22.786570Z","shell.execute_reply":"2025-05-28T08:36:22.791169Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Backup and Preprocessing\n\nCreating a backup copy and cleaning the title text by removing unwanted characters and normalizing whitespace.","metadata":{"_uuid":"5a2f3257-f8d8-4e98-abf3-b51d7716369a","_cell_guid":"89a20a82-12ce-4fb7-a998-f5a6ca7a8a29","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"data_copy = medium_data.copy()\nprint(\"Backup copy created successfully\")","metadata":{"_uuid":"e60fd960-fd51-4168-a294-87567355272a","_cell_guid":"f620767f-8358-4dc7-8b68-b048c97ba172","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.793512Z","iopub.execute_input":"2025-05-28T08:36:22.793755Z","iopub.status.idle":"2025-05-28T08:36:22.809023Z","shell.execute_reply.started":"2025-05-28T08:36:22.793735Z","shell.execute_reply":"2025-05-28T08:36:22.808314Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# medium_data = data_copy.copy()","metadata":{"_uuid":"f48a5b92-c9e7-481e-a670-24710ede0f23","_cell_guid":"b0714684-2587-4f18-a364-81d91d840c94","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.809663Z","iopub.execute_input":"2025-05-28T08:36:22.809901Z","iopub.status.idle":"2025-05-28T08:36:22.825531Z","shell.execute_reply.started":"2025-05-28T08:36:22.809868Z","shell.execute_reply":"2025-05-28T08:36:22.824847Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine all unwanted characters and whitespace patterns\nclean_pattern = re.compile(r'[\\u00a0\\u200a\\u200b\\u200c\\u200d\\u202f\\u2060\\ufeff\\t\\r\\n]+')\n\nmedium_data['title'] = medium_data['title'].apply(\n    lambda x: clean_pattern.sub(' ', x).strip()\n)\nprint(\"Text cleaning completed - removed special characters and normalized whitespace\")","metadata":{"_uuid":"0563999a-c046-4037-9129-af2fb6b44554","_cell_guid":"76d145b3-7ddb-4e95-8c65-9aa1a3bb0872","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.826388Z","iopub.execute_input":"2025-05-28T08:36:22.826663Z","iopub.status.idle":"2025-05-28T08:36:22.856346Z","shell.execute_reply.started":"2025-05-28T08:36:22.826638Z","shell.execute_reply":"2025-05-28T08:36:22.855527Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Sample cleaned titles:\")\nmedium_data['title']","metadata":{"_uuid":"8f08031a-2de2-4ae6-8cb9-5c0f04f65954","_cell_guid":"7dd1b0ee-95fc-4121-820e-9880729dc27f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.857197Z","iopub.execute_input":"2025-05-28T08:36:22.857453Z","iopub.status.idle":"2025-05-28T08:36:22.874448Z","shell.execute_reply.started":"2025-05-28T08:36:22.857429Z","shell.execute_reply":"2025-05-28T08:36:22.873759Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Text Tokenization\n\nConverting text data into numerical sequences using Keras Tokenizer. This creates a vocabulary mapping each unique word to a numerical index.","metadata":{"_uuid":"35527fd2-1b9f-4bc2-b970-1b6b412712a4","_cell_guid":"17496277-76b5-415e-8b19-18470e280232","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"tokenizer = Tokenizer(oov_token = '<oov>')\ntokenizer.fit_on_texts(medium_data['title'])\nprint(\"Tokenizer fitted on title texts\")","metadata":{"_uuid":"b771c4f0-d03c-4bf0-8df8-8f5333ffb294","_cell_guid":"4d4683b0-2077-4115-96b3-839e2ad0e9fb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.875164Z","iopub.execute_input":"2025-05-28T08:36:22.875433Z","iopub.status.idle":"2025-05-28T08:36:22.970152Z","shell.execute_reply.started":"2025-05-28T08:36:22.875406Z","shell.execute_reply":"2025-05-28T08:36:22.969611Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Word index mapping (first 10 entries):\")\nword_items = list(tokenizer.word_index.items())[:10]\nfor word, index in word_items:\n    print(f\"'{word}': {index}\")\ntokenizer.word_index","metadata":{"_uuid":"58614d32-0c92-473b-af34-3867dbf1a8ef","_cell_guid":"38142836-c9b7-456f-a3c4-f42d1dd25cc7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.970851Z","iopub.execute_input":"2025-05-28T08:36:22.971126Z","iopub.status.idle":"2025-05-28T08:36:22.985726Z","shell.execute_reply.started":"2025-05-28T08:36:22.971106Z","shell.execute_reply":"2025-05-28T08:36:22.985120Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_words = len(tokenizer.word_index)+1\nprint(f\"Total vocabulary size: {total_words}\")\ntotal_words","metadata":{"_uuid":"0aba7837-d030-478c-9c69-1cdbe03034ef","_cell_guid":"9e50fa3b-fc99-4f01-95a6-10e8bb69c373","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:22.988193Z","iopub.execute_input":"2025-05-28T08:36:22.988375Z","iopub.status.idle":"2025-05-28T08:36:23.001149Z","shell.execute_reply.started":"2025-05-28T08:36:22.988358Z","shell.execute_reply":"2025-05-28T08:36:23.000540Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## N-gram Sequence Generation\n\nCreating input sequences by generating all possible n-grams from each title. This allows the model to learn word patterns and dependencies within titles.","metadata":{"_uuid":"81dd7a07-593f-4595-b344-d6b11ae1d5ce","_cell_guid":"263d54bf-0bf6-4dd1-8db1-90f879ecac42","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"tokenized_sequences = []\nfor title in medium_data['title']:\n    sequences = tokenizer.texts_to_sequences([title])[0]    \n    for i in range(1, len(sequences)):\n        n_gram_sequence = sequences[:i+1]\n        tokenized_sequences.append(n_gram_sequence)\n\nprint(\"Total input sequences: \", len(tokenized_sequences))","metadata":{"_uuid":"035cf3da-a770-49e2-a4ba-56b916f3e4e1","_cell_guid":"c64a547c-0200-4626-8d4e-a1a7447336c1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.001811Z","iopub.execute_input":"2025-05-28T08:36:23.002061Z","iopub.status.idle":"2025-05-28T08:36:23.099108Z","shell.execute_reply.started":"2025-05-28T08:36:23.002035Z","shell.execute_reply":"2025-05-28T08:36:23.098458Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Sample tokenized sequences (first 5):\")\nfor i, seq in enumerate(tokenized_sequences[:5]):\n    print(f\"Sequence {i+1}: {seq}\")\ntokenized_sequences","metadata":{"_uuid":"1f3a2138-6c75-4004-85bd-edc90ffeb1e7","_cell_guid":"88b0d27a-47bd-4259-816b-17d730eae5af","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.099852Z","iopub.execute_input":"2025-05-28T08:36:23.100119Z","iopub.status.idle":"2025-05-28T08:36:23.150824Z","shell.execute_reply.started":"2025-05-28T08:36:23.100093Z","shell.execute_reply":"2025-05-28T08:36:23.150115Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sequence Padding\n\nPadding sequences to ensure uniform input length for the neural network. All sequences are padded to match the longest sequence length.","metadata":{"_uuid":"4bdedef2-2f91-4e99-8ea7-9688d69efa2c","_cell_guid":"7497097f-431d-4621-b685-9ef3b0c14e0d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"maxlen = max([len(x) for x in tokenized_sequences])\nprint(f\"Maximum sequence length: {maxlen}\")\nmaxlen","metadata":{"_uuid":"6a8b7f11-cf04-41a7-a6d8-958d296792a6","_cell_guid":"6f852c77-577a-4b69-b10e-a034b0c929ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-28T08:36:23.151585Z","iopub.execute_input":"2025-05-28T08:36:23.151926Z","iopub.status.idle":"2025-05-28T08:36:23.159344Z","shell.execute_reply.started":"2025-05-28T08:36:23.151880Z","shell.execute_reply":"2025-05-28T08:36:23.158709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"padded_sequences = pad_sequences(tokenized_sequences, maxlen = maxlen, padding=\"pre\")\nprint(\"Sample padded sequence:\")\nprint(padded_sequences[0])","metadata":{"_uuid":"1dc96e38-49c9-40dd-a790-f7365080a211","_cell_guid":"f577d9a9-6709-4885-8a12-3c52c7039e60","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.159997Z","iopub.execute_input":"2025-05-28T08:36:23.160311Z","iopub.status.idle":"2025-05-28T08:36:23.262089Z","shell.execute_reply.started":"2025-05-28T08:36:23.160295Z","shell.execute_reply":"2025-05-28T08:36:23.261249Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Original sequence length: {len(tokenized_sequences[0])}\")\nprint(f\"Padded sequence length: {len(padded_sequences[0])}\")","metadata":{"_uuid":"9f2fb779-16d1-46c5-8d56-c4c4bd5b2f21","_cell_guid":"f07b445c-4d03-4de4-b700-69a2c2b7bb4c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.262778Z","iopub.execute_input":"2025-05-28T08:36:23.263027Z","iopub.status.idle":"2025-05-28T08:36:23.267007Z","shell.execute_reply.started":"2025-05-28T08:36:23.263003Z","shell.execute_reply":"2025-05-28T08:36:23.266244Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Input-Output Split\n\nSplitting sequences into input features (X) and target labels (y). The last word of each sequence becomes the target that the model should predict.","metadata":{"_uuid":"faf0a27f-783f-4187-938f-e8353e93ff32","_cell_guid":"3acf2371-7dce-4a45-9814-c43c28eae0ff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"X = padded_sequences[:, :-1]\ny = padded_sequences[:, -1]\n\nprint(f\"Input shape (X): {X.shape}\")\nprint(f\"Target shape (y): {y.shape}\")\nX, y","metadata":{"_uuid":"7328d5fa-8221-4037-89dc-26fe460def79","_cell_guid":"797db8ad-ed83-4f1c-9044-7244c749fa70","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.267747Z","iopub.execute_input":"2025-05-28T08:36:23.267984Z","iopub.status.idle":"2025-05-28T08:36:23.283133Z","shell.execute_reply.started":"2025-05-28T08:36:23.267968Z","shell.execute_reply":"2025-05-28T08:36:23.282530Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## One-Hot Encoding\n\nConverting target labels to categorical format for multi-class classification. Each target word is represented as a one-hot vector.","metadata":{"_uuid":"18f33d21-76b5-4b7f-8cb5-25bd8e5af170","_cell_guid":"4ff0dd37-0532-4922-95ce-437e9adf0dea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"y = to_categorical(y, num_classes=total_words)\nprint(\"Target labels converted to categorical format\")","metadata":{"_uuid":"4325973e-efdc-4ead-b77a-acc22aac1be5","_cell_guid":"f63c721b-a42e-498d-85f0-e4432a307277","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.283821Z","iopub.execute_input":"2025-05-28T08:36:23.284296Z","iopub.status.idle":"2025-05-28T08:36:23.437161Z","shell.execute_reply.started":"2025-05-28T08:36:23.284277Z","shell.execute_reply":"2025-05-28T08:36:23.436354Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Sample one-hot encoded target:\")\nprint(y[0])\nprint(f\"One-hot vector length: {len(y[0])}\")","metadata":{"_uuid":"36b868de-e144-4894-b46d-ce01d593df2f","_cell_guid":"bbd80ec8-7c8b-4e6b-ae2e-0cfd9a497a5e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.438027Z","iopub.execute_input":"2025-05-28T08:36:23.438298Z","iopub.status.idle":"2025-05-28T08:36:23.442781Z","shell.execute_reply.started":"2025-05-28T08:36:23.438265Z","shell.execute_reply":"2025-05-28T08:36:23.442237Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_length = X.shape[1]\nprint(f\"Input sequence length for model: {input_length}\")\ninput_length","metadata":{"_uuid":"28add485-9240-4d08-92e4-9a698e46307c","_cell_guid":"eca65821-764d-4f0d-a89e-0d6719de1ba4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.443520Z","iopub.execute_input":"2025-05-28T08:36:23.443757Z","iopub.status.idle":"2025-05-28T08:36:23.459471Z","shell.execute_reply.started":"2025-05-28T08:36:23.443737Z","shell.execute_reply":"2025-05-28T08:36:23.458853Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Architecture\n\nBuilding a Bidirectional LSTM model for next-word prediction. The architecture includes:\n- Embedding layer for word representations\n- Bidirectional LSTM for capturing context from both directions\n- Dense output layer with softmax activation for word probability distribution","metadata":{"_uuid":"d83c8aae-1f6e-4691-ab09-d3d97a3cff05","_cell_guid":"3d4864ab-c4b2-42cc-80c3-f855ee06d06f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model = Sequential([\n    Embedding(input_dim=total_words, output_dim=100, input_shape=(input_length,)),\n    Bidirectional(LSTM(100)),\n    Dense(total_words, activation=\"softmax\")\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\nprint(\"Model architecture:\")\nmodel.summary()","metadata":{"_uuid":"51ab71c9-0c9a-4867-9a71-1312a19ba6f3","_cell_guid":"41f4a42a-64a1-4232-881e-526f7eea1aa1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:23.460102Z","iopub.execute_input":"2025-05-28T08:36:23.460320Z","iopub.status.idle":"2025-05-28T08:36:26.039643Z","shell.execute_reply.started":"2025-05-28T08:36:23.460305Z","shell.execute_reply":"2025-05-28T08:36:26.039096Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training\n\nTraining the model with 50 epochs, using 10% of data for validation to monitor performance and prevent overfitting.","metadata":{"_uuid":"b34aa471-1493-4c94-95d1-05242e49e6c2","_cell_guid":"b7904b57-1273-4c74-9aa3-c6f6ec44544c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"Starting model training...\")\nhistory = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.1, verbose=True)\nprint(\"Training completed!\")","metadata":{"_uuid":"9d9512bd-5144-4bc4-b4f0-579e75da8eec","_cell_guid":"ce52fec9-8903-48e5-910e-ca9d443f287d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:36:26.040348Z","iopub.execute_input":"2025-05-28T08:36:26.040574Z","iopub.status.idle":"2025-05-28T09:06:26.946607Z","shell.execute_reply.started":"2025-05-28T08:36:26.040550Z","shell.execute_reply":"2025-05-28T09:06:26.945747Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Visualization\n\nPlotting training history to visualize model performance over epochs and identify potential overfitting.","metadata":{"_uuid":"1e236826-1a44-4d91-9498-d8101ccd450d","_cell_guid":"88299310-1a84-49a8-a0ef-82a21c65f9e8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def plot_graphs(history, string):\n    \"\"\"\n    Plot training metrics over epochs.\n    \n    Args:\n        history: Training history object from model.fit()\n        string: Metric name to plot ('accuracy' or 'loss')\n    \"\"\"\n    plt.plot(history.history[string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.show()\n\nprint(\"Training accuracy over epochs:\")\nplot_graphs(history, \"accuracy\")\nprint(\"Training loss over epochs:\")\nplot_graphs(history, \"loss\")","metadata":{"_uuid":"cf64dc0f-23e0-4552-9674-10d76a5a4602","_cell_guid":"3dff51f1-82f5-4e1e-9102-dc71318dd408","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T09:11:27.690727Z","iopub.execute_input":"2025-05-28T09:11:27.691082Z","iopub.status.idle":"2025-05-28T09:11:27.917650Z","shell.execute_reply.started":"2025-05-28T09:11:27.691061Z","shell.execute_reply":"2025-05-28T09:11:27.917104Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Title Generation Function\n\nFunction to generate new title suggestions based on seed text using the trained model.","metadata":{"_uuid":"1535e5e0-724c-4822-a5be-d4b179a5f44b","_cell_guid":"2edc4558-cb09-40df-8aad-6de86feed80b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def generate_title(seed_text, next_words=10):\n    \"\"\"\n    Generate new title text based on seed input.\n    \n    Args:\n        seed_text (str): Starting text for title generation\n        next_words (int): Number of words to generate after seed text\n        \n    Returns:\n        str: Complete generated title including seed text\n    \"\"\"\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=input_length, padding='pre')\n        predicted = model.predict(token_list, verbose=0)\n        predicted_word_index = np.argmax(predicted, axis=1)[0]\n        \n        for word, index in tokenizer.word_index.items():\n            if index == predicted_word_index:\n                seed_text += \" \" + word\n                break\n    return seed_text","metadata":{"_uuid":"138fdc03-2d86-4235-9fd9-2fa843d332bf","_cell_guid":"617a32d6-87de-4895-88db-c4abe0ed2657","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-28T09:12:53.534298Z","iopub.execute_input":"2025-05-28T09:12:53.534583Z","iopub.status.idle":"2025-05-28T09:12:53.539681Z","shell.execute_reply.started":"2025-05-28T09:12:53.534563Z","shell.execute_reply":"2025-05-28T09:12:53.538872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Title Generation Examples\n\nTesting the trained model with different seed phrases to generate Medium article titles.","metadata":{"_uuid":"1b181a27-e912-4adf-8dbc-d6f95036bd1b","_cell_guid":"44c769df-711a-4f5e-9b94-9f5d3fc82727","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"Generated title examples:\")\nprint(\"Seed: 'how to' ->\", generate_title(\"how to\", 6))\nprint(\"Seed: 'deep learning' ->\", generate_title(\"deep learning\", 7))\nprint(\"Seed: 'What are' ->\", generate_title(\"What are\", 5))","metadata":{"_uuid":"8d961f86-f902-4f7d-a16c-39e38ddf027d","_cell_guid":"1e4e3522-62ec-4f01-85c9-48ef57c89b35","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T09:19:26.223798Z","iopub.execute_input":"2025-05-28T09:19:26.224405Z","iopub.status.idle":"2025-05-28T09:19:27.526165Z","shell.execute_reply.started":"2025-05-28T09:19:26.224383Z","shell.execute_reply":"2025-05-28T09:19:27.525512Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model and Tokenizer Saving\n\nSaving the trained model and tokenizer for future use and deployment.","metadata":{"_uuid":"ef66bb22-6ef4-4757-ae55-44e2c54aca92","_cell_guid":"944d77fd-6cc3-48e8-81a6-e45a0c108c7a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import json\ntoken_json = tokenizer.to_json()\nwith open('tokenizer.json', 'w') as f:\n    f.write(token_json)\nprint(\"Tokenizer saved to 'tokenizer.json'\")","metadata":{"_uuid":"051f8a60-1733-45bc-866d-e993d16c7bc4","_cell_guid":"a505e0d4-48d0-4729-b15d-20b69b66766d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T09:19:35.757745Z","iopub.execute_input":"2025-05-28T09:19:35.758314Z","iopub.status.idle":"2025-05-28T09:19:35.782464Z","shell.execute_reply.started":"2025-05-28T09:19:35.758292Z","shell.execute_reply":"2025-05-28T09:19:35.781875Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"medium_title_gen.h5\")\nprint(\"Model saved to 'medium_title_gen.h5'\")","metadata":{"_uuid":"ab7ff960-d9f8-4f6e-819e-57f3ce7cbea1","_cell_guid":"503eaa4e-35fd-48b9-b275-a09e2b06c376","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-28T09:20:05.466726Z","iopub.execute_input":"2025-05-28T09:20:05.467013Z","iopub.status.idle":"2025-05-28T09:20:05.558511Z","shell.execute_reply.started":"2025-05-28T09:20:05.466993Z","shell.execute_reply":"2025-05-28T09:20:05.557718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Summary\n\nSuccessfully implemented and trained a Bidirectional LSTM model for Medium article title generation. The model can generate contextually relevant titles based on seed text input, making it useful for content creators seeking title inspiration.","metadata":{"_uuid":"fc17a3a8-1815-42d2-83c7-28137656ba5a","_cell_guid":"1377133d-d23f-4cc9-912b-fe8530056a28","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}